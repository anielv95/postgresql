{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant who always generate similar email to the one provided\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"Hi John,\n",
    "\n",
    "Very happy to hear from you, could we have our meeting at your 12:30 or 1:00 pm on Tuesday - Friday?\n",
    "\n",
    "Regards\"\"\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-70B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "def create_synthetic_emails(email_list:list):\n",
    "    synthetic_emails = []\n",
    "    for ith_email in email_list:\n",
    "        messages = messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant who always generate similar email to the one provided\"},\n",
    "            {\"role\": \"user\", \"content\": f'{ith_email}'},\n",
    "        ]\n",
    "        outputs = pipeline(\n",
    "            messages,\n",
    "            max_new_tokens=256,\n",
    "        )\n",
    "        synthetic_emails.append(outputs[0][\"generated_text\"][-1])\n",
    "    return synthetic_emails\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"```json\\n{\\n  \\\"Subject\\\": \\\"Sports Roundup\\\",\\n  \\\"Body\\\": \\\"## üèÄ‚öæüèà‚öΩ üéæüèìüè∏üèèüèí\\n\\nThis week in sports, there were some exciting developments across various disciplines. Here\\'s a quick rundown:\\n\\n**üèÄ NBA:** \\n* The Golden State Warriors clinched their 8th NBA championship in their history, defeating the Boston Celtics in a thrilling six-game series. Stephen Curry was once again phenomenal, earning Finals MVP honors.\\n\\n**‚öæ MLB:** \\n* Shohei Ohtani continues to dominate both at the plate and on the mound. He recently hit his 30th home run of the season and is also among the league leaders in wins and ERA as a pitcher.\\n* The New York Yankees are running away with the American League East, holding a comfortable lead over their rivals. Aaron Judge is on pace for a historic season, chasing Roger Maris\\'s 61-homer record.\\n\\n**üèà NFL:** \\n* Preseason NFL games are underway, giving fans a glimpse of what to expect in the upcoming season. Several rookies have impressed so far, including quarterbacks Trevor Lawrence and Zach Wilson.\\n* The reigning Super Bowl champion Los Angeles Rams are looking to repeat, but they face stiff competition from other contenders like the Kansas City Chiefs and Tampa Bay Buccaneers.\\n\\n**‚öΩ FIFA World Cup:** \\n* With less than a year to go until the FIFA World Cup in Qatar, excitement is building across the globe. Several nations have already qualified, including host Qatar, Brazil, and Argentina.\\n* Fans are eagerly anticipating the performance of star players like Lionel Messi, Cristiano Ronaldo, and Kylian Mbapp√©.\\n## Other Sports News\\n\\n* In tennis, Novak Djokovic continues his reign at the top of the men\\'s rankings. He recently won his 21st Grand Slam title at Wimbledon, tying the record held by Roger Federer and Rafael Nadal.\\n* The Tokyo Olympics were a resounding success, showcasing incredible athletic performances across diverse sports.\\n* Cricket fans around the world are looking forward to the upcoming ICC Men\\'s T20 World Cup in Australia. India and England are among the favorites to win the tournament.\\n\\nLet me know if you\\'d like more in-depth information on any specific sport or event.\\\"\\n}\\n```\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = re.split(\"`+json\",text)\n",
    "ans2 = re.split(\"`+$\",ans[1])\n",
    "ans3 = json.loads(ans2[0],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_json(text):\n",
    "    error = \"\"\n",
    "    problematic_text = \"\"\n",
    "    try:\n",
    "        answer = re.split(\"`+json\",text)\n",
    "        answer = re.split(\"`+$\",answer[1])\n",
    "        answer = json.loads(answer[0])\n",
    "    except Exception as e:\n",
    "        error = e\n",
    "        problematic_text = text\n",
    "        answer = json.loads(answer[0],strict=False)\n",
    "    return answer,problematic_text,error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_json(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample.json\", \"w\") as outfile:\n",
    "    json.dump(out[0], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sample.json', 'r') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = {ith_topic:[] for ith_topic in [1,2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "PROJECT_ID = os.environ[\"PROJECT_ID\"]\n",
    "REGION = os.environ[\"REGION\"]\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, ChatSession\n",
    "import os \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "PROJECT_ID = os.environ[\"PROJECT_ID\"]\n",
    "REGION = os.environ[\"REGION\"]\n",
    "vertexai.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_chat_response(chat: ChatSession, prompt: str):\n",
    "    response = chat.send_message(prompt)\n",
    "    return response.text\n",
    "\n",
    "def get_emails(topics,number_emails):\n",
    "\n",
    "    model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "\n",
    "    emails = {ith_topic:[] for ith_topic in topics}\n",
    "    unparsed_emails = {ith_topic:[] for ith_topic in topics}\n",
    "    wrong_format = {ith_topic:[] for ith_topic in topics}\n",
    "    \n",
    "    for i in range(number_emails):\n",
    "        print(i)\n",
    "        for ith_topic in topics:\n",
    "            chat = model.start_chat()\n",
    "            prompt = f\"You're a helpful assistant. Write a short email in json format about {ith_topic}. Always use 'Subject' and 'Body' as the keys in the answer\"\n",
    "            ans_ = get_chat_response(chat, prompt)\n",
    "            ans_, problematic_text, error = get_json(ans_)\n",
    "            if len(problematic_text)==0:\n",
    "                unparsed_emails[ith_topic].append({\"text\":problematic_text,\"error\":error})\n",
    "            try:\n",
    "                assert len(list(ans_.keys()))==2\n",
    "                assert \"Subject\" in list(ans_.keys())\n",
    "                assert \"Body\" in list(ans_.keys())\n",
    "                emails[ith_topic].append(ans_)\n",
    "            except Exception as e:\n",
    "                wrong_format[ith_topic].append({\"json\":ans_,\"error\":e})\n",
    "    return emails, unparsed_emails, wrong_format\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics =[\"sports\",\"vegetarian\"]\n",
    "ans = get_emails(topics,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
